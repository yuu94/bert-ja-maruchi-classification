{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN8BHSaITvnZ"
   },
   "source": [
    "# 概要\n",
    "ここでは、GoogleColaboratoryの\n",
    "とGoogleDriveを使用して、BERTを用いた日本語文章の多値分類を行います。  \n",
    "日本語学習済みモデルは 京都大学 黒橋・河原研究所が公開している`BERT日本語Pretrainedモデル`を、形態素解析器は同研究室が公開している`JUMAN`を使用します。  \n",
    "  \n",
    "GoogleDriveに学習済みモデルとデータセットを保存するため、1.6GB以上の空きが必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HslOXENpULAp"
   },
   "source": [
    "# 全体の流れ\n",
    "1. 形態素解析器のインストール\n",
    "1. GoogleDriveをマウント\n",
    "1. データセット/BERT日本語学習済みモデルをGoogleDriveへ保存\n",
    "1. データセットをBERT向けのフォーマットに変換\n",
    "1. BERTのリポジトリをClone\n",
    "1. プログラムの改変\n",
    "1. trainデータを使用した、学習済みモデルのfine-tuning\n",
    "1. テストデータの予測\n",
    "1. 予測結果の検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "va_GGpURWbXk"
   },
   "source": [
    "## 形態素解析器のインストール\n",
    "京都大学 黒橋・河原研究所が公開している`BERT日本語Pretrainedモデル`では、形態素解析器に`JUMAN`を使用する必要がある為、インストールを行います。  \n",
    "詳細については、以下をご確認ください。  \n",
    "[BERT日本語Pretrainedモデル - KUROHASHI-KAWAHARA LAB - 詳細](http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT日本語Pretrainedモデル#r6199008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1TAj1JzTEnY"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc2/jumanpp-2.0.0-rc2.tar.xz && \\\n",
    "tar xJvf jumanpp-2.0.0-rc2.tar.xz && \\\n",
    "rm jumanpp-2.0.0-rc2.tar.xz && \\\n",
    "cd jumanpp-2.0.0-rc2/ && \\\n",
    "mkdir bld && \\\n",
    "cd bld && \\\n",
    "cmake .. \\\n",
    "  -DCMAKE_BUILD_TYPE=Release \\\n",
    "  -DCMAKE_INSTALL_PREFIX=/usr/local && \\\n",
    "make && \\\n",
    "sudo make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NYlUeuRWnvE"
   },
   "source": [
    "インストールの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEJQIuuI7ZFk"
   },
   "outputs": [],
   "source": [
    "!jumanpp -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlowのバージョン変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79_qRkEYWqse"
   },
   "source": [
    "### pyknpのインストール\n",
    "PythonでJUMANを実行する為のライブラリです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc2rNEwbSZ2u"
   },
   "outputs": [],
   "source": [
    "! pip install pyknp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbMi4cm2VWhz"
   },
   "source": [
    "## GoogleDriveのマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc_0XErvrSm9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eng0HQNPWxfI"
   },
   "source": [
    "作業ディレクトリの作成と移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGscLUd8GQB3"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /content/drive/'My Drive'/brrt/livedoor_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1581317907864,
     "user": {
      "displayName": "Yuu T",
      "photoUrl": "",
      "userId": "11907369725828200330"
     },
     "user_tz": -540
    },
    "id": "QAwo05Z1rZ9X",
    "outputId": "d6ea0ffd-12d9-4134-fed7-c4d7e1b2fe67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/bert/livedoor_news\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/'My Drive'/bert/livedoor_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FnXJPglBVdKn"
   },
   "source": [
    "## データセット/BERT日本語学習済みモデルをGoogleDriveへ保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBCn-CFFJydU"
   },
   "source": [
    "### livedoor newsコーパスのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSCPXJnGJBPF"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "livedoor_news_url = \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
    "urllib.request.urlretrieve(livedoor_news_url, \"ldcc-20140209.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBKkDC_DXCac"
   },
   "source": [
    "### BERT日本語Pretrainedモデルのダウンロードと解凍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McDr7MBwxJNh"
   },
   "outputs": [],
   "source": [
    "kyoto_u_bert_url = \"http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE.zip\"\n",
    "urllib.request.urlretrieve(kyoto_u_bert_url, \"Japanese_L-12_H-768_A-12_E-30_BPE.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reZhrTatNOrw"
   },
   "outputs": [],
   "source": [
    "!unzip Japanese_L-12_H-768_A-12_E-30_BPE.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju4RBQMwIfPI"
   },
   "source": [
    "## データセットをBERT向けのフォーマットに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmJJNBNaW0On"
   },
   "source": [
    "### TSVファイルの作成\n",
    "下記の記事を参考に作成しました。  \n",
    "[BERT多言語モデルで日本語文章の二値分類を試す](https://qiita.com/knok/items/9e3b4505d6b8f813943d)\n",
    "\n",
    "  GoogleDriveに保存されるまで少し時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvGqjX_QrtKP"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import csv\n",
    "import re\n",
    "\n",
    "\n",
    "target_genre = [\n",
    "                \"dokujo-tsushin\",\n",
    "                \"it-life-hack\",\n",
    "                \"kaden-channel\",\n",
    "                \"livedoor-homme\",\n",
    "                \"movie-enter\",\n",
    "                \"peachy\",\n",
    "                \"smax\",\n",
    "                \"sports-watch\",\n",
    "                \"topic-news\"\n",
    "                ]\n",
    "\n",
    "fname_list = [[] for i in range(len(target_genre))]\n",
    "\n",
    "tsv_fname = \"all.tsv\"\n",
    "\n",
    "brackets_tail = re.compile('【[^】]*】$')\n",
    "brackets_head = re.compile('^【[^】]*】')\n",
    "\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(brackets_head, '',re.sub(brackets_tail, '', inp))\n",
    "\n",
    "    return output\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.decode('utf-8'))\n",
    "\n",
    "    return title[:-1]\n",
    "\n",
    "with tarfile.open(\"ldcc-20140209.tar.gz\") as tf:\n",
    "    for ti in tf:\n",
    "        if \"LICENSE.txt\" in ti.name:\n",
    "            continue\n",
    "        elif \"CHANGES.txt\" in ti.name:\n",
    "            continue\n",
    "        elif \"README.txt\" in ti.name:\n",
    "            continue\n",
    "        else:\n",
    "            for i, t in enumerate(target_genre):\n",
    "                if target_genre[i] in ti.name and ti.name.endswith(\".txt\"):\n",
    "                    fname_list[i].append(ti.name)\n",
    "                    continue\n",
    "\n",
    "    with open(tsv_fname, \"w\") as wf:\n",
    "        writer = csv.writer(wf, delimiter='\\t')\n",
    "        for i, fcategory in enumerate(fname_list):\n",
    "            for name in fcategory:\n",
    "                f = tf.extractfile(name)\n",
    "                title = read_title(f)\n",
    "                row = [target_genre[i], i, '', title]\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJ641Q2VW52V"
   },
   "source": [
    "### trainデータ/devデータ/testデータの分割  \n",
    "all.tsvがGoogleDriveに生成されてから実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0UoGkyjuqu8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(100)\n",
    "with open(\"all.tsv\", 'r') as f, open(\"rand-all.tsv\", \"w\") as wf:\n",
    "    lines = f.readlines()\n",
    "    random.shuffle(lines)\n",
    "    for line in lines:\n",
    "        wf.write(line)\n",
    "\n",
    "random.seed(101)\n",
    "\n",
    "train_fname, dev_fname, test_fname = [\"train.tsv\", \"dev.tsv\", \"test.tsv\"]\n",
    "\n",
    "with open(\"rand-all.tsv\") as f, open(train_fname, \"w\") as tf, open(dev_fname, \"w\") as df, open(test_fname, \"w\") as ef:\n",
    "    ef.write(\"class\\tsentence\\n\")\n",
    "    for line in f:\n",
    "        v = random.randint(0, 9)\n",
    "        if v == 8:\n",
    "            df.write(line)\n",
    "        elif v == 9:\n",
    "            ef.write(line)\n",
    "        else:\n",
    "            tf.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFdnuNZ1V1bl"
   },
   "source": [
    "## BERTのリポジトリをClone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ekj4tLpJW8BD"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/google-research/bert.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuYKlaMEWM99"
   },
   "source": [
    "## プログラムの改変\n",
    "[Qiitaの記事](https://qiita.com/Yuu94/items/0e5cff226bd3cc8fb08c)を参考に、`run_classifier.py`と`tokenization.py`を改変してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_k0jXwmXLW7"
   },
   "source": [
    "## trainデータを使用した、学習済みモデルのfine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlOa10I3NQKd"
   },
   "outputs": [],
   "source": [
    "!python bert/run_classifier_livedoor.py \\\n",
    "--task_name=livedoor \\\n",
    "--do_train=true \\\n",
    "--do_eval=true \\\n",
    "--data_dir=./ \\\n",
    "--vocab_file=./Japanese_L-12_H-768_A-12_E-30_BPE/vocab.txt \\\n",
    "--bert_config_file=./Japanese_L-12_H-768_A-12_E-30_BPE/bert_config.json \\\n",
    "--init_checkpoint=./Japanese_L-12_H-768_A-12_E-30_BPE/bert_model.ckpt \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size=32 \\\n",
    "--learning_rate=2e-5 \\\n",
    "--num_train_epochs=3.0 \\\n",
    "--output_dir=./tmp/livedoor_news_output_fine \\\n",
    "--do_lower_case False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuBNof8YXP01"
   },
   "source": [
    "## テストデータの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIXqfJmWGUTU"
   },
   "outputs": [],
   "source": [
    "!python bert/run_classifier_livedoor.py \\\n",
    "  --task_name=livedoor \\\n",
    "  --do_predict=true \\\n",
    "  --data_dir=./ \\\n",
    "  --vocab_file=./Japanese_L-12_H-768_A-12_E-30_BPE/vocab.txt \\\n",
    "  --bert_config_file=./Japanese_L-12_H-768_A-12_E-30_BPE/bert_config.json \\\n",
    "  --init_checkpoint=./tmp/livedoor_news_output_fine \\\n",
    "  --max_seq_length=128 \\\n",
    "  --output_dir=tmp/livedoor_news_output_predic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odtE3ltgMjHK"
   },
   "source": [
    "## 予測結果の検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inxp0xd7Mlyz"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"./test.tsv\") as f, open(\"tmp/livedoor_news_output_predic/test_results.tsv\") as rf:\n",
    "  test = csv.reader(f, delimiter = '\\t')\n",
    "  test_result = csv.reader(rf, delimiter = '\\t')\n",
    "\n",
    "  # 正解データの抽出\n",
    "  next(test)\n",
    "  test_list = [int(row[1]) for row in test ]\n",
    "\n",
    "  # 予測結果を抽出\n",
    "  result_list = []\n",
    "  for result in test_result:\n",
    "    max_index = np.argmax(result)\n",
    "    result_list.append(max_index)\n",
    "\n",
    "  # 分類した予測結果(カテゴリNo)を出力\n",
    "  with open('tmp/livedoor_news_output_predic/test_results.csv', 'w') as of:\n",
    "    writer = csv.writer(of)\n",
    "    for row in result_list:\n",
    "      writer.writerow([row])\n",
    "\n",
    "  test_count = len(test_list)\n",
    "  result_correct_answer_list = [result for test, result in zip(test_list, result_list) if test == result]\n",
    "  result_correct_answer_count = len(result_correct_answer_list)\n",
    "  print(\"正解率: \", result_correct_answer_count / test_count)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "livedoor_news_multi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
